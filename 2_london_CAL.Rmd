---
title: "london_CAL"
output: html_document
date: "2023-07-13"
---

This file contains first part of the London-level CAL calculation (from raw data to travel time estimates to EDF). EDF to CAL conversion and further analysis using the CAL result can be found in the 3_london_CAL_cont.Rmd.  

```{r}
# to increase available memory to java for r5r to 20GB
options(java.parameters = "-Xmx20G")
```

# load packages 

```{r}
library(r5r)
library(sf)
library(data.table)
library(dplyr)
library(tmap)
library(grid)
library(stringr)
#library(devtools)
#devtools::install_github("PublicHealthDataGeek/CycleInfraLnd")
library(CycleInfraLnd)
```

# Work Package 1: access + wait time estimates

## 1. read in OD points and geo boundary data

The pre-processed origin and destination points are read in. 
 
```{r}
origin_sf <- fread(file.path("input/origin.csv"))%>%
  st_as_sf(.,coords = c("lat", "lon"), crs = 4326)%>%
  select("id","geometry")

towncentres_cen <- fread(file.path("input/destination.csv"))%>%
  st_as_sf(.,coords = c("lat", "lon"), crs = 4326)%>%
  select("id","geometry")
```

Since this file is for Camden only,  select the points in Camden by GSS_CODE = E09000007, and then map the points on map to check if they are in the correct. Since it is now data frame with lat lon info, the point data will be converted to sf object for easy mapping. 

Then get the london boundary for mapping. 

```{r}
london <- st_read(here::here("data/London_Boroughs.gpkg"))%>%
  st_transform(., 4326)%>%
  select("objectid","geom")
```
Spatial clipping to ensure all POIs are within the london boundary. 

```{r}
origin_sf <- origin_sf[london,]
towncentres_cen <- towncentres_cen[london,]
```

In total 159446 grid centroids in London and 209 town centres. 

r5r requires the id of points to be in character, not integer.. 

```{r}
origin_sf$id <- origin_sf$id%>%
  as.character(.)

towncentres_cen$id <- towncentres_cen$id%>%
  as.character(.)
```

## 2. build the network

Since the data folder is too large to upload on GitHub, shared links of the used data are attached accordingly with data source stated in this rmd. 

The data input folder contains (processed in the 1_data_processing.Rmd): 

1. origin and destination csv files 

2. OSM network pbf 

3. London GTFS zip 

4. elevation tif (processed in the additional_data_processing.Rmd)

The above files are for r5r travel time estimates. The other files are generated by the setup_r5 function to establish the network data.  

```{r}
# Indicate the path where OSM and GTFS data are stored
r5r_core <- setup_r5(data_path = "C:/Users/99/Documents/CASA/dissertation_test/input")

# or the input directory can be accessed from the shared OneDrive folder here (updated on 29 July, 2023): https://liveuclac-my.sharepoint.com/:f:/g/personal/zcfther_ucl_ac_uk/Em3mws5GdBVJoyMIZv4S4wwBAACSWSiw5kED4jIvOYGzhg?e=qA5jYG
```

It takes longer time to get the r5r_core for the first time, and after that r5r will use the cached network.dat in the same directory of data_path to get the network. 

## 3. routing and travel time prediction

Before calculating the travel time, some parameters are set. Note the departure data depends on the service calendar file in the GTFS zip file. The file (data downloaded using codes in additional_data_processing.rmd) stores the service frequency data from 2023-05-22 to 2023-12-23. 

```{r}
# routing inputs
max_walk_time <- 12 # minutes
max_bike_time <- 12 # minutes
max_trip_duration <- 60 # minutes

# departure datetime (peak time)
departure_datetime = as.POSIXct("26-05-2023 08:00:00", 
                                format = "%d-%m-%Y %H:%M:%S",
                                tz = "GMT")

# departure datetime (off-peak time)
departure_datetime_off = as.POSIXct("27-05-2023 11:00:00", 
                                format = "%d-%m-%Y %H:%M:%S",
                                tz = "GMT")
```

### Peak time time estimates

Estimate the travel time by walking. This will be the travel time of all the possible OD pairs from all PTAL grid centroids to all town centres within 12 min walking distance and 60 min travel time. For walking as the only mode, this can be viewed as the short local trips in the compact city notion. For public transit mode, this can be viewed as the long distance, sustainable, multi-modal trips. For this mode, the access and wait time will be kept as the component of total access time, resembling the sustainable trip within the neighbourhood. 

```{r}
# estimate travel time matrix for walk
ttm_walk_simple <- expanded_travel_time_matrix(r5r_core = r5r_core,   
                          origins = origin_sf,
                          destinations = towncentres_cen,    
                          mode = c("WALK","TRANSIT"),
                          max_walk_time = max_walk_time,
                          max_trip_duration = max_trip_duration,
                          walk_speed = 4.8,
                          bike_speed = 13,
                          departure_datetime = departure_datetime,
                          breakdown = TRUE)

TAT_walk <- ttm_walk_simple%>%
  mutate(TAT_walk = case_when(!str_detect(`routes`, "WALK") ~ access_time + wait_time,
                    TRUE ~ total_time))%>%
  select("from_id","to_id","TAT_walk")
```

```{r}
# estimate travel time matrix for bike
ttm_bike_simple <- expanded_travel_time_matrix(r5r_core = r5r_core,   
                          origins = origin_sf,
                          destinations = towncentres_cen,    
                          mode = c("BICYCLE","TRANSIT"),
                          max_bike_time = max_bike_time,
                          max_trip_duration = max_trip_duration,
                          walk_speed = 4.8,
                          bike_speed = 13,
                          departure_datetime = departure_datetime,
                          breakdown = TRUE)

TAT_bike <- ttm_bike_simple%>%
  mutate(TAT_bike = case_when(!str_detect(`routes`, "BICYCLE") ~ access_time + wait_time,
                    TRUE ~ total_time))%>%
  select("from_id","to_id","TAT_bike")
```

# Work Package 2: parking time estimates

```{r}
cid_parking = get_cid_points(type = "cycle_parking")%>%  # select parking point data from the database
  select("FEATURE_ID","PRK_CPT","BOROUGH","geometry")
```

```{r}
# routing inputs
max_bike_time_park <- 5 # minutes
max_trip_duration_park <- 10 # minutes

# departure datetime
# being the same as travel time estimates for OD pairs above, so no need to set again. 
```

```{r}
cid_parking$id <- cid_parking$FEATURE_ID%>%
  as.character(.)
```

Parking time is the same for peak and offpeak time in this r5r time estimate. 

```{r}
# estimate travel time matrix for walk
ttm_park <- travel_time_matrix(r5r_core = r5r_core,   
                          origins = towncentres_cen,
                          destinations = cid_parking,    
                          mode = c("bicycle"),
                          max_bike_time = max_bike_time_park,
                          max_trip_duration = max_trip_duration_park,
                          departure_datetime = departure_datetime)

head(ttm_park, n = 10)
```
```{r}
ttm_park <-ttm_park %>%
  left_join(.,cid_parking,by= join_by("to_id"=="id"))%>%
  st_as_sf(., crs = 4326)%>%
  st_drop_geometry()%>%
  select("from_id","to_id","travel_time_p50","PRK_CPT")%>%
  mutate(to_park_time = case_when(travel_time_p50 == 0 ~ 0.1, 
                                  TRUE ~ travel_time_p50))%>% 
  #travel time set to 0.5 when it is 0, to avoid infinity value when calculating the relative importance 
  mutate(RI = PRK_CPT/to_park_time)

```

```{r}
park_index <- ttm_park%>%
  group_by(from_id)%>%
  summarise(park_index =0.5*max(RI)+0.5*sum(RI))%>%
  left_join(.,towncentres_cen,by= join_by("from_id"=="id"))%>%
  st_as_sf()%>%
  mutate(park_index = coalesce(park_index, 0))
```

```{r}
tmap_mode("plot")

map_park_index = 
tm_shape(park_index) +
  tm_dots(size = 0.5, col = "park_index",palette="-RdYlBu", style = "quantile", n=6) +
tm_shape(london) +
  tm_polygons(col = NA, alpha = 0)

map_park_index
```

```{r}
first_quantile = quantile(park_index$park_index, 0.25)
median = quantile(park_index$park_index, 0.5)
third_quantile = quantile(park_index$park_index, 0.75)
```

```{r}
park_index<-park_index%>%
  mutate(park_time = case_when(park_index < first_quantile ~ 5, 
                               park_index < median & park_index >= first_quantile ~ 3.5,
                               park_index < third_quantile & park_index >= median ~ 2,
                                  TRUE ~ 0.5))

ttm_park_index_df <- park_index%>%
   st_drop_geometry()
```

# export the parking time estimate into csv

```{r}
st_write(ttm_park_index_df, "london_parking.csv")
```

# Work Package 3: CAL conversion 

merge bike time and park time

```{r}
ttm_park_index_df <- fread(file.path("london_parking.csv"))

ttm_park_index_df$from_id <- ttm_park_index_df$from_id%>%
  as.character(.)

TAT_bike_park <- TAT_bike%>%
  left_join(.,ttm_park_index_df, join_by("to_id"=="from_id"))%>%
  select("from_id", "to_id", "TAT_bike", "park_time")
```

merge walk time

```{r}
ttm_all <- full_join(TAT_walk,TAT_bike_park,by=c("from_id","to_id"))
```

```{r}
#the number of OD pairs that are not reachable by foot or through walk + PT. (can be accessed only by bike)
sum(is.na(ttm_all$TAT_walk))
```

```{r}
#the number of OD pairs that are not reachable by bike or through bike + PT. (can be accessed only by walking)
sum(is.na(ttm_all$TAT_bike))
```

```{r}
summary(ttm_all)
```

```{r}
ttm_all<- ttm_all%>%
  mutate(park_time2 = case_when(!is.na(park_time) ~ park_time,
                                !is.na(TAT_bike) & is.na(park_time) ~ 2,
                                 TRUE ~ NA))%>%
  select("from_id","to_id","TAT_walk", "TAT_bike", "park_time2")%>%
  rename("park_time" = "park_time2")

summary(ttm_all)
```
```{r}
ttm_all_peak <- ttm_all %>%
  mutate(access_time = case_when (!is.na(TAT_walk) ~ TAT_walk,
                           !is.na(TAT_bike) ~ TAT_bike + park_time,
                           TRUE ~ TAT_walk))%>%
  mutate(TAT = case_when (access_time == 0 ~ 0.1,
                           TRUE ~ access_time)) %>%
  mutate(EDF = 0.5 * (60 / TAT))%>%
  select("from_id","to_id","TAT_walk","TAT_bike","park_time","TAT" ,"EDF")
```

```{r}
ttm_all_ai <- ttm_all_peak %>%
  group_by(from_id)%>%
  summarize(AI=0.5*max(EDF)+0.5*sum(EDF))

summary(ttm_all_ai)
```


```{r}
st_write(ttm_all_ai, "london_ai_peak.csv")

# then the data objects in the environment can be removed to free up space
# rm(ttm_walk_simple)
# rm(ttm_walk_simple_off)
# rm(ttm_bike_simple)
# rm(ttm_all)
# rm(ttm_all_test)
# rm(TAT_bike)
# rm(TAT_bike_park)
# rm(TAT_walk)

```
### Off-Peak time time estimates

repeat the same process 

```{r}
# estimate travel time matrix for walk
ttm_walk_simple_off <- expanded_travel_time_matrix(r5r_core = r5r_core,   
                          origins = origin_sf,
                          destinations = towncentres_cen,    
                          mode = c("WALK","TRANSIT"),
                          max_walk_time = max_walk_time,
                          max_trip_duration = max_trip_duration,
                          walk_speed = 4.8,
                          bike_speed = 13,
                          departure_datetime = departure_datetime_off,
                          breakdown = TRUE)

TAT_walk_off <- ttm_walk_simple_off%>%
  mutate(TAT_walk_off = case_when(!str_detect(`routes`, "WALK") ~ access_time + wait_time,
                    TRUE ~ total_time))%>%
  select("from_id","to_id","TAT_walk_off")
```


```{r}
# estimate travel time matrix for bike
ttm_bike_simple_off <- expanded_travel_time_matrix(r5r_core = r5r_core,   
                          origins = origin_sf,
                          destinations = towncentres_cen,    
                          mode = c("BICYCLE","TRANSIT"),
                          max_bike_time = max_bike_time,
                          max_trip_duration = max_trip_duration,
                          walk_speed = 4.8,
                          bike_speed = 13,
                          departure_datetime = departure_datetime_off,
                          breakdown = TRUE)

TAT_bike_off <- ttm_bike_simple_off%>%
  mutate(TAT_bike_off = case_when(!str_detect(`routes`, "BICYCLE") ~ access_time + wait_time,
                    TRUE ~ total_time))%>%
  select("from_id","to_id","TAT_bike_off")
```

merge bike time and park time

```{r}
ttm_park_index_df <- fread(file.path("london_parking.csv"))
ttm_park_index_df$from_id <- ttm_park_index_df$from_id%>%
  as.character(.)

TAT_bike_park_off <- TAT_bike_off%>%
  left_join(.,ttm_park_index_df, join_by("to_id"=="from_id"))%>%
  select("from_id", "to_id", "TAT_bike_off", "park_time")
```

merge walk time

```{r}
ttm_all_off <- full_join(TAT_walk_off,TAT_bike_park_off,by=c("from_id","to_id"))
```


```{r}
#the number of OD pairs that are not reachable by foot or through walk + PT. (can be accessed only by bike)
sum(is.na(ttm_all_off$TAT_walk_off))
```

```{r}
#the number of OD pairs that are not reachable by bike or through bike + PT. (can be accessed only by walking)
sum(is.na(ttm_all_off$TAT_bike_off))
```

```{r}
summary(ttm_all_off)
```

```{r}
ttm_all_off<- ttm_all_off%>%
  mutate(park_time2 = case_when(!is.na(park_time) ~ park_time,
                                !is.na(TAT_bike_off) & is.na(park_time) ~ 2,
                                 TRUE ~ NA))%>%
  select("from_id","to_id","TAT_walk_off", "TAT_bike_off", "park_time2")%>%
  rename("park_time" = "park_time2")

summary(ttm_all_off)
```

```{r}
ttm_all_offpeak <- ttm_all_off %>%
  mutate(access_time = case_when (!is.na(TAT_walk_off) ~ TAT_walk_off,
                           !is.na(TAT_bike_off) ~ TAT_bike_off + park_time,
                           TRUE ~ TAT_walk_off))%>%
  mutate(TAT = case_when (access_time == 0 ~ 0.1,
                           TRUE ~ access_time)) %>%
  mutate(EDF_off = 0.5 * (60 / TAT))%>%
  select("from_id","to_id","TAT_walk_off","TAT_bike_off","park_time","TAT" ,"EDF_off")
```

```{r}
ttm_all_ai_offpeak <- ttm_all_offpeak %>%
  group_by(from_id)%>%
  summarize(AI_off=0.5*max(EDF_off)+0.5*sum(EDF_off))

summary(ttm_all_ai_offpeak)
```

```{r}
st_write(ttm_all_ai_offpeak, "london_ai_offpeak.csv")
```

# export the data into csv

```{r}
ttm_all_peak <- fread(file.path("london_ai_peak.csv"))%>%
  select("from_id", "AI")

ttm_all_off <- fread(file.path("london_ai_offpeak.csv"))%>%
  select("from_id","AI_off")

ttm <- full_join(ttm_all_peak,ttm_all_off,by="from_id")

summary(ttm)
```

```{r}
st_write(ttm, "london_ai.csv")
```

Then the conversion to CAL from EDF is calculated in another file names EDF_to_CAL.Rmd. The analysis of the processed data is also conducted in that file.  

---

After processing, remove r5r_core in the environment to avoid taking up memories. 
```{r}
r5r::stop_r5(r5r_core)
rJava::.jgc(R.gc = TRUE)
```

